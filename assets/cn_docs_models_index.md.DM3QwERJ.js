import{_ as d,c as r,o as a,af as e}from"./chunks/framework.BMktmvug.js";const c=JSON.parse('{"title":"🚀 模型列表","description":"","frontmatter":{},"headers":[],"relativePath":"cn/docs/models/index.md","filePath":"cn/docs/models/index.md"}'),o={name:"cn/docs/models/index.md"};function n(l,t,h,s,i,g){return a(),r("div",null,t[0]||(t[0]=[e('<h1 id="🚀-模型列表" tabindex="-1">🚀 模型列表 <a class="header-anchor" href="#🚀-模型列表" aria-label="Permalink to &quot;🚀 模型列表&quot;">​</a></h1><p>Chaterm 支持多种模型提供商，为您提供灵活的 AI 编程体验。从内置模型到自定义集成，满足不同场景的需求。</p><h2 id="✨-内置模型" tabindex="-1">✨ 内置模型 <a class="header-anchor" href="#✨-内置模型" aria-label="Permalink to &quot;✨ 内置模型&quot;">​</a></h2><p>Chaterm 内置了多个优质的代码模型，开箱即用，无需额外配置：</p><h3 id="🧠-思维链模型" tabindex="-1">🧠 思维链模型 <a class="header-anchor" href="#🧠-思维链模型" aria-label="Permalink to &quot;🧠 思维链模型&quot;">​</a></h3><p>这些模型具备深度推理能力，能够逐步分析问题并给出详细的解决方案：</p><table tabindex="0"><thead><tr><th>模型</th><th>特点</th><th>适用场景</th><th>推理能力</th></tr></thead><tbody><tr><td><strong>DeepSeek-R1 (thinking)</strong></td><td>🎯 具备深度推理能力的先进模型</td><td>复杂算法设计、架构分析</td><td>⭐⭐⭐⭐⭐</td></tr><tr><td><strong>DeepSeek-V3.1 (thinking)</strong></td><td>💡 支持复杂代码分析</td><td>大型项目重构、性能优化</td><td>⭐⭐⭐⭐⭐</td></tr><tr><td><strong>GLM-4.5 (thinking)</strong></td><td>🔍 强大的逻辑推理能力</td><td>代码审查、问题诊断</td><td>⭐⭐⭐⭐</td></tr><tr><td><strong>Qwen-Plus (thinking)</strong></td><td>🚀 阿里云通义千问思维链模型</td><td>多语言开发、跨平台项目</td><td>⭐⭐⭐⭐</td></tr></tbody></table><h3 id="⚡-标准模型" tabindex="-1">⚡ 标准模型 <a class="header-anchor" href="#⚡-标准模型" aria-label="Permalink to &quot;⚡ 标准模型&quot;">​</a></h3><p>快速响应的标准模型，适合日常编程任务：</p><table tabindex="0"><thead><tr><th>模型</th><th>特点</th><th>适用场景</th><th>响应速度</th></tr></thead><tbody><tr><td><strong>GLM-4.5</strong></td><td>🎨 优秀的代码生成能力</td><td>快速原型开发、功能实现</td><td>⚡⚡⚡⚡</td></tr><tr><td><strong>Qwen-Plus</strong></td><td>🏆 高性能代码生成模型</td><td>企业级应用开发</td><td>⚡⚡⚡</td></tr><tr><td><strong>Qwen-Turbo</strong></td><td>⚡ 快速响应的轻量级模型</td><td>实时编程辅助、快速迭代</td><td>⚡⚡⚡⚡⚡</td></tr></tbody></table><h2 id="🔧-添加自定义模型" tabindex="-1">🔧 添加自定义模型 <a class="header-anchor" href="#🔧-添加自定义模型" aria-label="Permalink to &quot;🔧 添加自定义模型&quot;">​</a></h2><p>您可以在设置中添加更多模型提供商，扩展 Chaterm 的功能。支持多种集成方式，满足不同需求：</p><h3 id="🌐-云端模型集成" tabindex="-1">🌐 云端模型集成 <a class="header-anchor" href="#🌐-云端模型集成" aria-label="Permalink to &quot;🌐 云端模型集成&quot;">​</a></h3><h4 id="_1-🔗-litellm-集成" tabindex="-1">1. 🔗 LiteLLM 集成 <a class="header-anchor" href="#_1-🔗-litellm-集成" aria-label="Permalink to &quot;1. 🔗 LiteLLM 集成&quot;">​</a></h4><p>通过 LiteLLM 可以连接多种模型提供商，支持统一的 API 接口：</p><table tabindex="0"><thead><tr><th>配置项</th><th>说明</th><th>是否必需</th></tr></thead><tbody><tr><td><strong>URL 地址</strong></td><td>LiteLLM 服务端点</td><td>✅ 必需</td></tr><tr><td><strong>API Key</strong></td><td>访问密钥</td><td>✅ 必需</td></tr><tr><td><strong>模型名称</strong></td><td>要使用的具体模型</td><td>✅ 必需</td></tr></tbody></table><p><strong>优势：</strong> 统一接口，支持多种模型提供商</p><h4 id="_2-🤖-openai-集成" tabindex="-1">2. 🤖 OpenAI 集成 <a class="header-anchor" href="#_2-🤖-openai-集成" aria-label="Permalink to &quot;2. 🤖 OpenAI 集成&quot;">​</a></h4><p>直接连接 OpenAI 服务，享受官方支持：</p><table tabindex="0"><thead><tr><th>配置项</th><th>说明</th><th>是否必需</th></tr></thead><tbody><tr><td><strong>OpenAI URL 地址</strong></td><td>OpenAI API 端点</td><td>✅ 必需</td></tr><tr><td><strong>OpenAI API Key</strong></td><td>OpenAI 访问密钥</td><td>✅ 必需</td></tr><tr><td><strong>模型名称</strong></td><td>GPT-4、GPT-3.5 等</td><td>✅ 必需</td></tr></tbody></table><p><strong>优势：</strong> 官方支持，稳定可靠</p><h4 id="_3-☁️-amazon-bedrock" tabindex="-1">3. ☁️ Amazon Bedrock <a class="header-anchor" href="#_3-☁️-amazon-bedrock" aria-label="Permalink to &quot;3. ☁️ Amazon Bedrock&quot;">​</a></h4><p>使用 AWS Bedrock 服务，企业级解决方案：</p><table tabindex="0"><thead><tr><th>配置项</th><th>说明</th><th>是否必需</th></tr></thead><tbody><tr><td><strong>AWS Access Key</strong></td><td>AWS 访问密钥</td><td>✅ 必需</td></tr><tr><td><strong>AWS Secret Key</strong></td><td>AWS 秘密密钥</td><td>✅ 必需</td></tr><tr><td><strong>AWS Session Token</strong></td><td>会话令牌</td><td>🔶 可选</td></tr><tr><td><strong>AWS 区域</strong></td><td>服务区域</td><td>✅ 必需</td></tr><tr><td><strong>自定义 VPC 端点</strong></td><td>私有网络端点</td><td>🔶 可选</td></tr><tr><td><strong>跨区域推理</strong></td><td>多区域部署</td><td>🔶 可选</td></tr><tr><td><strong>模型名称</strong></td><td>Bedrock 模型</td><td>✅ 必需</td></tr></tbody></table><p><strong>优势：</strong> 企业级安全，高可用性</p><h4 id="_4-🚀-deepseek-集成" tabindex="-1">4. 🚀 DeepSeek 集成 <a class="header-anchor" href="#_4-🚀-deepseek-集成" aria-label="Permalink to &quot;4. 🚀 DeepSeek 集成&quot;">​</a></h4><p>连接 DeepSeek 官方 API，享受先进模型：</p><table tabindex="0"><thead><tr><th>配置项</th><th>说明</th><th>是否必需</th></tr></thead><tbody><tr><td><strong>DeepSeek API Key</strong></td><td>DeepSeek 访问密钥</td><td>✅ 必需</td></tr><tr><td><strong>模型名称</strong></td><td>DeepSeek 模型</td><td>✅ 必需</td></tr></tbody></table><p><strong>优势：</strong> 先进模型，推理能力强</p><h3 id="🏠-本地模型部署" tabindex="-1">🏠 本地模型部署 <a class="header-anchor" href="#🏠-本地模型部署" aria-label="Permalink to &quot;🏠 本地模型部署&quot;">​</a></h3><h4 id="_5-🦙-ollama-本地部署" tabindex="-1">5. 🦙 Ollama 本地部署 <a class="header-anchor" href="#_5-🦙-ollama-本地部署" aria-label="Permalink to &quot;5. 🦙 Ollama 本地部署&quot;">​</a></h4><p>使用本地部署的 Ollama 模型，保护数据隐私：</p><table tabindex="0"><thead><tr><th>配置项</th><th>说明</th><th>是否必需</th></tr></thead><tbody><tr><td><strong>Ollama URL 地址</strong></td><td>本地 Ollama 服务地址</td><td>✅ 必需</td></tr><tr><td><strong>模型名称</strong></td><td>本地模型名称</td><td>✅ 必需</td></tr></tbody></table><p><strong>优势：</strong> 数据隐私，离线可用</p><h2 id="📋-使用说明" tabindex="-1">📋 使用说明 <a class="header-anchor" href="#📋-使用说明" aria-label="Permalink to &quot;📋 使用说明&quot;">​</a></h2><h3 id="快速开始" tabindex="-1">快速开始 <a class="header-anchor" href="#快速开始" aria-label="Permalink to &quot;快速开始&quot;">​</a></h3><ol><li><strong>进入设置页面</strong> - 点击右上角设置图标</li><li><strong>选择&quot;模型&quot;选项卡</strong> - 在左侧菜单中找到模型设置</li><li><strong>点击&quot;添加模型&quot;按钮</strong> - 开始添加新的模型配置</li><li><strong>选择相应的提供商</strong> - 根据需求选择合适的模型提供商</li><li><strong>填写必要的配置信息</strong> - 按照表格要求填写配置项</li><li><strong>保存并测试连接</strong> - 验证配置是否正确</li></ol><h3 id="🔧-配置技巧" tabindex="-1">🔧 配置技巧 <a class="header-anchor" href="#🔧-配置技巧" aria-label="Permalink to &quot;🔧 配置技巧&quot;">​</a></h3><ul><li><strong>API Key 安全</strong>：使用环境变量存储敏感信息</li><li><strong>连接测试</strong>：配置完成后务必进行连接测试</li><li><strong>模型切换</strong>：可以配置多个模型，根据需要切换使用</li><li><strong>性能监控</strong>：关注模型响应时间和使用成本</li></ul><h2 id="🎯-模型选择建议" tabindex="-1">🎯 模型选择建议 <a class="header-anchor" href="#🎯-模型选择建议" aria-label="Permalink to &quot;🎯 模型选择建议&quot;">​</a></h2><h3 id="按使用场景选择" tabindex="-1">按使用场景选择 <a class="header-anchor" href="#按使用场景选择" aria-label="Permalink to &quot;按使用场景选择&quot;">​</a></h3><table tabindex="0"><thead><tr><th>使用场景</th><th>推荐模型</th><th>理由</th></tr></thead><tbody><tr><td><strong>日常编程</strong></td><td>Qwen-Turbo</td><td>⚡ 响应快速，成本低</td></tr><tr><td><strong>复杂任务</strong></td><td>DeepSeek-R1 (thinking)</td><td>🧠 推理能力强，分析深入</td></tr><tr><td><strong>本地部署</strong></td><td>Ollama</td><td>🔒 数据隐私，离线可用</td></tr><tr><td><strong>企业级应用</strong></td><td>Amazon Bedrock</td><td>🏢 稳定可靠，安全合规</td></tr><tr><td><strong>多语言开发</strong></td><td>Qwen-Plus (thinking)</td><td>🌍 支持多语言，理解能力强</td></tr><tr><td><strong>快速原型</strong></td><td>GLM-4.5</td><td>🚀 生成速度快，适合迭代</td></tr></tbody></table><h3 id="按性能需求选择" tabindex="-1">按性能需求选择 <a class="header-anchor" href="#按性能需求选择" aria-label="Permalink to &quot;按性能需求选择&quot;">​</a></h3><h4 id="🚀-追求速度" tabindex="-1">🚀 追求速度 <a class="header-anchor" href="#🚀-追求速度" aria-label="Permalink to &quot;🚀 追求速度&quot;">​</a></h4><ul><li><strong>Qwen-Turbo</strong> - 最快响应</li><li><strong>GLM-4.5</strong> - 平衡性能与质量</li></ul><h4 id="🧠-追求质量" tabindex="-1">🧠 追求质量 <a class="header-anchor" href="#🧠-追求质量" aria-label="Permalink to &quot;🧠 追求质量&quot;">​</a></h4><ul><li><strong>DeepSeek-R1 (thinking)</strong> - 最强推理</li><li><strong>DeepSeek-V3.1 (thinking)</strong> - 复杂分析</li></ul><h4 id="💰-追求成本效益" tabindex="-1">💰 追求成本效益 <a class="header-anchor" href="#💰-追求成本效益" aria-label="Permalink to &quot;💰 追求成本效益&quot;">​</a></h4><ul><li><strong>Qwen-Turbo</strong> - 成本最低</li><li><strong>Ollama 本地</strong> - 无使用费用</li></ul><h4 id="🔒-追求隐私" tabindex="-1">🔒 追求隐私 <a class="header-anchor" href="#🔒-追求隐私" aria-label="Permalink to &quot;🔒 追求隐私&quot;">​</a></h4><ul><li><strong>Ollama 本地</strong> - 完全本地化</li><li><strong>Amazon Bedrock</strong> - 企业级安全</li></ul>',51)]))}const u=d(o,[["render",n]]);export{c as __pageData,u as default};
