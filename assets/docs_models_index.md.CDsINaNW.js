import{_ as e,c as o,o as a,af as r}from"./chunks/framework.BMktmvug.js";const u=JSON.parse('{"title":"🚀 Model List","description":"","frontmatter":{},"headers":[],"relativePath":"docs/models/index.md","filePath":"docs/models/index.md"}'),i={name:"docs/models/index.md"};function n(d,t,s,l,c,g){return a(),o("div",null,t[0]||(t[0]=[r('<h1 id="🚀-model-list" tabindex="-1">🚀 Model List <a class="header-anchor" href="#🚀-model-list" aria-label="Permalink to &quot;🚀 Model List&quot;">​</a></h1><p>Chaterm supports multiple model providers, offering you a flexible AI programming experience. From built-in models to custom integrations, meeting different scenario needs.</p><h2 id="✨-built-in-models" tabindex="-1">✨ Built-in Models <a class="header-anchor" href="#✨-built-in-models" aria-label="Permalink to &quot;✨ Built-in Models&quot;">​</a></h2><p>Chaterm comes with multiple high-quality code models out of the box, ready to use without additional configuration:</p><h3 id="🧠-chain-of-thought-models" tabindex="-1">🧠 Chain-of-Thought Models <a class="header-anchor" href="#🧠-chain-of-thought-models" aria-label="Permalink to &quot;🧠 Chain-of-Thought Models&quot;">​</a></h3><p>These models have deep reasoning capabilities and can analyze problems step by step to provide detailed solutions:</p><table tabindex="0"><thead><tr><th>Model</th><th>Features</th><th>Use Cases</th><th>Reasoning Ability</th></tr></thead><tbody><tr><td><strong>DeepSeek-R1 (thinking)</strong></td><td>🎯 Advanced model with deep reasoning capabilities</td><td>Complex algorithm design, architecture analysis</td><td>⭐⭐⭐⭐⭐</td></tr><tr><td><strong>DeepSeek-V3.1 (thinking)</strong></td><td>💡 Supports complex code analysis</td><td>Large project refactoring, performance optimization</td><td>⭐⭐⭐⭐⭐</td></tr><tr><td><strong>GLM-4.5 (thinking)</strong></td><td>🔍 Powerful logical reasoning capabilities</td><td>Code review, problem diagnosis</td><td>⭐⭐⭐⭐</td></tr><tr><td><strong>Qwen-Plus (thinking)</strong></td><td>🚀 Alibaba Cloud&#39;s Tongyi Qianwen chain-of-thought model</td><td>Multi-language development, cross-platform projects</td><td>⭐⭐⭐⭐</td></tr></tbody></table><h3 id="⚡-standard-models" tabindex="-1">⚡ Standard Models <a class="header-anchor" href="#⚡-standard-models" aria-label="Permalink to &quot;⚡ Standard Models&quot;">​</a></h3><p>Fast-response standard models suitable for daily programming tasks:</p><table tabindex="0"><thead><tr><th>Model</th><th>Features</th><th>Use Cases</th><th>Response Speed</th></tr></thead><tbody><tr><td><strong>GLM-4.5</strong></td><td>🎨 Excellent code generation capabilities</td><td>Rapid prototyping, feature implementation</td><td>⚡⚡⚡⚡</td></tr><tr><td><strong>Qwen-Plus</strong></td><td>🏆 High-performance code generation model</td><td>Enterprise application development</td><td>⚡⚡⚡</td></tr><tr><td><strong>Qwen-Turbo</strong></td><td>⚡ Fast-response lightweight model</td><td>Real-time programming assistance, rapid iteration</td><td>⚡⚡⚡⚡⚡</td></tr></tbody></table><h2 id="🔧-add-custom-models" tabindex="-1">🔧 Add Custom Models <a class="header-anchor" href="#🔧-add-custom-models" aria-label="Permalink to &quot;🔧 Add Custom Models&quot;">​</a></h2><p>You can add more model providers in settings to extend Chaterm&#39;s functionality. Supports multiple integration methods to meet different needs:</p><h3 id="🌐-cloud-model-integration" tabindex="-1">🌐 Cloud Model Integration <a class="header-anchor" href="#🌐-cloud-model-integration" aria-label="Permalink to &quot;🌐 Cloud Model Integration&quot;">​</a></h3><h4 id="_1-🔗-litellm-integration" tabindex="-1">1. 🔗 LiteLLM Integration <a class="header-anchor" href="#_1-🔗-litellm-integration" aria-label="Permalink to &quot;1. 🔗 LiteLLM Integration&quot;">​</a></h4><p>Connect to various model providers through LiteLLM with unified API interface:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>URL Address</strong></td><td>LiteLLM service endpoint</td><td>✅ Required</td></tr><tr><td><strong>API Key</strong></td><td>Access key</td><td>✅ Required</td></tr><tr><td><strong>Model Name</strong></td><td>Specific model to use</td><td>✅ Required</td></tr></tbody></table><p><strong>Advantages:</strong> Unified interface, supports multiple model providers</p><h4 id="_2-🤖-openai-integration" tabindex="-1">2. 🤖 OpenAI Integration <a class="header-anchor" href="#_2-🤖-openai-integration" aria-label="Permalink to &quot;2. 🤖 OpenAI Integration&quot;">​</a></h4><p>Direct connection to OpenAI services with official support:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>OpenAI URL Address</strong></td><td>OpenAI API endpoint</td><td>✅ Required</td></tr><tr><td><strong>OpenAI API Key</strong></td><td>OpenAI access key</td><td>✅ Required</td></tr><tr><td><strong>Model Name</strong></td><td>GPT-4, GPT-3.5, etc.</td><td>✅ Required</td></tr></tbody></table><p><strong>Advantages:</strong> Official support, stable and reliable</p><h4 id="_3-☁️-amazon-bedrock" tabindex="-1">3. ☁️ Amazon Bedrock <a class="header-anchor" href="#_3-☁️-amazon-bedrock" aria-label="Permalink to &quot;3. ☁️ Amazon Bedrock&quot;">​</a></h4><p>Using AWS Bedrock services, enterprise-grade solution:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>AWS Access Key</strong></td><td>AWS access key</td><td>✅ Required</td></tr><tr><td><strong>AWS Secret Key</strong></td><td>AWS secret key</td><td>✅ Required</td></tr><tr><td><strong>AWS Session Token</strong></td><td>Session token</td><td>🔶 Optional</td></tr><tr><td><strong>AWS Region</strong></td><td>Service region</td><td>✅ Required</td></tr><tr><td><strong>Custom VPC Endpoint</strong></td><td>Private network endpoint</td><td>🔶 Optional</td></tr><tr><td><strong>Cross-Region Inference</strong></td><td>Multi-region deployment</td><td>🔶 Optional</td></tr><tr><td><strong>Model Name</strong></td><td>Bedrock model</td><td>✅ Required</td></tr></tbody></table><p><strong>Advantages:</strong> Enterprise-grade security, high availability</p><h4 id="_4-🚀-deepseek-integration" tabindex="-1">4. 🚀 DeepSeek Integration <a class="header-anchor" href="#_4-🚀-deepseek-integration" aria-label="Permalink to &quot;4. 🚀 DeepSeek Integration&quot;">​</a></h4><p>Connect to DeepSeek official API, enjoy advanced models:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>DeepSeek API Key</strong></td><td>DeepSeek access key</td><td>✅ Required</td></tr><tr><td><strong>Model Name</strong></td><td>DeepSeek model</td><td>✅ Required</td></tr></tbody></table><p><strong>Advantages:</strong> Advanced models, strong reasoning capabilities</p><h3 id="🏠-local-model-deployment" tabindex="-1">🏠 Local Model Deployment <a class="header-anchor" href="#🏠-local-model-deployment" aria-label="Permalink to &quot;🏠 Local Model Deployment&quot;">​</a></h3><h4 id="_5-🦙-ollama-local-deployment" tabindex="-1">5. 🦙 Ollama Local Deployment <a class="header-anchor" href="#_5-🦙-ollama-local-deployment" aria-label="Permalink to &quot;5. 🦙 Ollama Local Deployment&quot;">​</a></h4><p>Using locally deployed Ollama models, protect data privacy:</p><table tabindex="0"><thead><tr><th>Configuration Item</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><strong>Ollama URL Address</strong></td><td>Local Ollama service address</td><td>✅ Required</td></tr><tr><td><strong>Model Name</strong></td><td>Local model name</td><td>✅ Required</td></tr></tbody></table><p><strong>Advantages:</strong> Data privacy, offline available</p><h2 id="📋-usage-instructions" tabindex="-1">📋 Usage Instructions <a class="header-anchor" href="#📋-usage-instructions" aria-label="Permalink to &quot;📋 Usage Instructions&quot;">​</a></h2><h3 id="quick-start" tabindex="-1">Quick Start <a class="header-anchor" href="#quick-start" aria-label="Permalink to &quot;Quick Start&quot;">​</a></h3><ol><li><strong>Go to Settings Page</strong> - Click the settings icon in the top right corner</li><li><strong>Select &quot;Models&quot; Tab</strong> - Find model settings in the left menu</li><li><strong>Click &quot;Add Model&quot; Button</strong> - Start adding new model configuration</li><li><strong>Choose the Corresponding Provider</strong> - Select appropriate model provider based on needs</li><li><strong>Fill in Necessary Configuration Information</strong> - Fill in configuration items according to table requirements</li><li><strong>Save and Test Connection</strong> - Verify configuration is correct</li></ol><h3 id="🔧-configuration-tips" tabindex="-1">🔧 Configuration Tips <a class="header-anchor" href="#🔧-configuration-tips" aria-label="Permalink to &quot;🔧 Configuration Tips&quot;">​</a></h3><ul><li><strong>API Key Security</strong>: Use environment variables to store sensitive information</li><li><strong>Connection Testing</strong>: Always perform connection test after configuration</li><li><strong>Model Switching</strong>: Configure multiple models and switch as needed</li><li><strong>Performance Monitoring</strong>: Monitor model response time and usage costs</li></ul><h2 id="🎯-model-selection-recommendations" tabindex="-1">🎯 Model Selection Recommendations <a class="header-anchor" href="#🎯-model-selection-recommendations" aria-label="Permalink to &quot;🎯 Model Selection Recommendations&quot;">​</a></h2><h3 id="select-by-use-case" tabindex="-1">Select by Use Case <a class="header-anchor" href="#select-by-use-case" aria-label="Permalink to &quot;Select by Use Case&quot;">​</a></h3><table tabindex="0"><thead><tr><th>Use Case</th><th>Recommended Model</th><th>Reason</th></tr></thead><tbody><tr><td><strong>Daily Programming</strong></td><td>Qwen-Turbo</td><td>⚡ Fast response, low cost</td></tr><tr><td><strong>Complex Tasks</strong></td><td>DeepSeek-R1 (thinking)</td><td>🧠 Strong reasoning capabilities, deep analysis</td></tr><tr><td><strong>Local Deployment</strong></td><td>Ollama</td><td>🔒 Data privacy, offline available</td></tr><tr><td><strong>Enterprise Applications</strong></td><td>Amazon Bedrock</td><td>🏢 Stable and reliable, security compliant</td></tr><tr><td><strong>Multi-language Development</strong></td><td>Qwen-Plus (thinking)</td><td>🌍 Multi-language support, strong understanding</td></tr><tr><td><strong>Rapid Prototyping</strong></td><td>GLM-4.5</td><td>🚀 Fast generation, suitable for iteration</td></tr></tbody></table><h3 id="select-by-performance-needs" tabindex="-1">Select by Performance Needs <a class="header-anchor" href="#select-by-performance-needs" aria-label="Permalink to &quot;Select by Performance Needs&quot;">​</a></h3><h4 id="🚀-pursuing-speed" tabindex="-1">🚀 Pursuing Speed <a class="header-anchor" href="#🚀-pursuing-speed" aria-label="Permalink to &quot;🚀 Pursuing Speed&quot;">​</a></h4><ul><li><strong>Qwen-Turbo</strong> - Fastest response</li><li><strong>GLM-4.5</strong> - Balanced performance and quality</li></ul><h4 id="🧠-pursuing-quality" tabindex="-1">🧠 Pursuing Quality <a class="header-anchor" href="#🧠-pursuing-quality" aria-label="Permalink to &quot;🧠 Pursuing Quality&quot;">​</a></h4><ul><li><strong>DeepSeek-R1 (thinking)</strong> - Strongest reasoning</li><li><strong>DeepSeek-V3.1 (thinking)</strong> - Complex analysis</li></ul><h4 id="💰-pursuing-cost-efficiency" tabindex="-1">💰 Pursuing Cost Efficiency <a class="header-anchor" href="#💰-pursuing-cost-efficiency" aria-label="Permalink to &quot;💰 Pursuing Cost Efficiency&quot;">​</a></h4><ul><li><strong>Qwen-Turbo</strong> - Lowest cost</li><li><strong>Ollama Local</strong> - No usage fees</li></ul><h4 id="🔒-pursuing-privacy" tabindex="-1">🔒 Pursuing Privacy <a class="header-anchor" href="#🔒-pursuing-privacy" aria-label="Permalink to &quot;🔒 Pursuing Privacy&quot;">​</a></h4><ul><li><strong>Ollama Local</strong> - Complete localization</li><li><strong>Amazon Bedrock</strong> - Enterprise-grade security</li></ul><h2 id="💡-best-practices" tabindex="-1">💡 Best Practices <a class="header-anchor" href="#💡-best-practices" aria-label="Permalink to &quot;💡 Best Practices&quot;">​</a></h2><h3 id="model-combination-usage" tabindex="-1">Model Combination Usage <a class="header-anchor" href="#model-combination-usage" aria-label="Permalink to &quot;Model Combination Usage&quot;">​</a></h3><ul><li><strong>Development Phase</strong>: Use fast models for rapid iteration</li><li><strong>Code Review</strong>: Use chain-of-thought models for deep analysis</li><li><strong>Production Environment</strong>: Use stable and reliable enterprise-grade models</li></ul><h3 id="cost-optimization" tabindex="-1">Cost Optimization <a class="header-anchor" href="#cost-optimization" aria-label="Permalink to &quot;Cost Optimization&quot;">​</a></h3><ul><li><strong>Local Models</strong>: Suitable for frequently used scenarios</li><li><strong>Cloud Models</strong>: Suitable for occasional complex tasks</li><li><strong>Hybrid Usage</strong>: Choose appropriate models based on task complexity</li></ul><h3 id="security-considerations" tabindex="-1">Security Considerations <a class="header-anchor" href="#security-considerations" aria-label="Permalink to &quot;Security Considerations&quot;">​</a></h3><ul><li><strong>Sensitive Data</strong>: Prioritize local models</li><li><strong>Enterprise Environment</strong>: Use compliance-compliant models</li><li><strong>API Security</strong>: Regularly rotate API keys</li></ul>',58)]))}const p=e(i,[["render",n]]);export{u as __pageData,p as default};
